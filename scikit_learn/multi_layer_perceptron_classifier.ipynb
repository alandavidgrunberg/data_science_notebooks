{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa96c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural network accuracy: 0.8\n",
      "\n",
      "tuned neural network accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier # Multi Layer Perceptron Classifier \n",
    "\n",
    "# create artifical dataset\n",
    "X, y = make_classification(n_features=2, n_informative=2, n_redundant=0, random_state=3) # 'make_classification ' generates a classification dataset. 'n_features=2' makes two features, 'n_informative=2' makes both relevant to the target, 'n_redundant=0' makes neither just combinations of the informative features. default 100 samples, 2 target class memberships/labels. assign generated samples (feature matrix) to X, corresponding class memberships/labels (target array) to y\n",
    "\n",
    "\n",
    "## neural network classification\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)\n",
    "\n",
    "# instantiate neural network\n",
    "mlp= MLPClassifier(max_iter=1500, random_state=7) \n",
    "\n",
    "# default 'max_iter' is 200, not enough iterations for neural network to converge on optimal coefficients, change to 1500. \n",
    "# 'random_state' hold for coefficient (weights and biases) initialization. \n",
    "# default one hidden layer with 100 neurons, 'relu' activation. \n",
    "# 2 nuerons in input layer because dataset has two features. \n",
    "# 1 neuron in output layer because binary classification. \n",
    "# binary classification, so defaults output layer 'logistic' activation. \n",
    "# therefore neural network shape is: \n",
    "\n",
    "#   input layer  ->  hidden layer  ->  output layer\n",
    "#   2 neurons        100 neurons       1 neuron\n",
    "#                    relu activation   logistic activation\n",
    "\n",
    "# fit neural network\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# evaluate neural network\n",
    "print(\"neural network accuracy:\", mlp.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "\n",
    "## tuning neural network\n",
    "\n",
    "mlp= MLPClassifier(max_iter=1500, hidden_layer_sizes=(200,50), activation='tanh', alpha=0.00001, random_state=7) \n",
    "\n",
    "# match previous random state so neural networks can be compared. \n",
    "#'hidden_layer_sizes=' set two hidden layers, first with 200 neurons, second with 50 neurons. \n",
    "# 'activation=' set activation function as 'tanh' \n",
    "# 'alpha=' set iteration step size: how much the neural network changes the coefficients at each iteration while converging on optimal coefficients.\n",
    "# if the value is too small, may never converge on the optimal solution. if the value is too large, may miss the optimal solution. \n",
    "# default value is 0.0001 (decreasing alpha often requires an increase in 'max_iter='. now neural network shape is: \n",
    "\n",
    "#   input layer  ->  hidden layer  ->  hidden layer  ->  output layer\n",
    "#   2 neurons        200 neurons       50 neurons        1 neuron\n",
    "#                    tanh activation   tanh activation   logistic activation\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"tuned neural network accuracy:\", mlp.score(X_test, y_test))\n",
    "\n",
    "# code and comments by github.com/alandavidgrunberg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
