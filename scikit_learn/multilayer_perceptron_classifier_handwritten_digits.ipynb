{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac25e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*zeros and ones only*\n",
      "\n",
      "feature matrix X: (360, 64)\n",
      "target array y: (360,)\n",
      "\n",
      "\n",
      "first image:\n",
      "\n",
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
      "\n",
      "0\n",
      "\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "\n",
      "\n",
      "second image:\n",
      "\n",
      "1\n",
      "\n",
      "[[ 0.  0.  0. 12. 13.  5.  0.  0.]\n",
      " [ 0.  0.  0. 11. 16.  9.  0.  0.]\n",
      " [ 0.  0.  3. 15. 16.  6.  0.  0.]\n",
      " [ 0.  7. 15. 16. 16.  2.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  3.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  0. 11. 16. 10.  0.  0.]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.metrics import  confusion_matrix\n",
    "\n",
    "\n",
    "X, y = load_digits(n_class=2, return_X_y=True) # 'load_digits' dataset contains 10 classes: digits 0 through 9. 'n_class=2' selects only the first 2 digits: 0 and 1. 'return_X_y' returns (data, target) tuple. Unpacked and assigned to variables X, y\n",
    "\n",
    "print(\"*zeros and ones only*\")\n",
    "print()\n",
    "print(\"feature matrix X:\", X.shape) # 360 datapoints with 64 features each\n",
    "print(\"target array y:\", y.shape) # 360 targets\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"first image:\")\n",
    "print()\n",
    "print( X[0]) # show first datapoint's feature array. each datapoint is an 8 x 8 pixels grayscale image of a 0 or 1. the features are 64 values from 0 (black) to 16 (white). \n",
    "print()\n",
    "print(y[0]) # show target class label of first datapoint (0)\n",
    "print()\n",
    "print(X[0].reshape(8, 8)) # it's easier to make out the digit in the image if we reshape the array to 8 x 8\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"second image:\")\n",
    "print()\n",
    "print(y[1]) # show target class label of second datapoint (1)\n",
    "print()\n",
    "print(X[1].reshape(8, 8)) # second datapoint's feature array (reshaped to 8 x 8)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# *you can view the images directly by plotting them with matplotlib (not shown)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62fa1463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 predictions: [0 1 0 1 1]\n",
      "first 5 targets:     [0 1 0 1 1]\n",
      "model accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "## predicting digits (0 or 1) with neural network \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2) # train/test split\n",
    "\n",
    "mlp = MLPClassifier() # instantiate model. default one hidden layer with 100 neurons, 'relu' activation. 64 neurons in input layer because dataset has 64 features. 1 neuron in output layer because binary classification. defaults output layer 'logistic' activation because binary classification. therefore, neural network shape is:\n",
    "#                                    input layer  ->  hidden layer  ->  output layer\n",
    "#                                    64 neurons       100 neurons       1 neuron\n",
    "#                                                     relu activation   logistic activation\n",
    "\n",
    "\n",
    "\n",
    "mlp.fit(X_train, y_train) # fit model \n",
    "\n",
    "print(\"first 5 predictions:\", mlp.predict(X_test[0:5])) # first 5 predictions\n",
    "print(\"first 5 targets:    \", y_test[0:5]) # first 5 targets (actual values)\n",
    "print(\"model accuracy: \", mlp.score(X_test, y_test)) # model accuracy, 100%!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c76d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*all digits, zero through nine*\n",
      "\n",
      "first 5 predictions: [4 0 9 1 8]\n",
      "first 5 targets:     [4 0 9 1 4]\n",
      "model accuracy:  0.96\n",
      "\n",
      "wrongly predicted values: [4 4 8 4 4 6 9 9 4 3 5 3 9 9 5 5 9 3]\n",
      "wrongly predicted as:     [8 1 2 8 7 1 5 1 9 8 9 5 7 3 4 1 8 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## predicting digits (1 through 9) with neural network\n",
    "\n",
    "X, y = load_digits(return_X_y=True) # load dataset, this time the whole set 1 through 9, data and targets unpacked and assigned to X, y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2) # train/test split on whole dataset\n",
    "\n",
    "mlp = MLPClassifier(random_state=3) # instantiate model. default one hidden layer with 100 neurons, 'relu' activation. 64 neurons in input layer because dataset has 64 features. 1 neuron in output layer because binary classification. defaults output layer 'softmax' activation because multilabel classification (10 target labels, digits 0 through 9). therefore, neural network shape is:\n",
    "#\n",
    "#                                    input layer  ->  hidden layer  ->  output layer\n",
    "#                                    64 neurons       100 neurons       10 neurons\n",
    "#                                                     relu activation   softmax activation\n",
    "#                                                                       (highest output neuron chosen)\n",
    "\n",
    "mlp.fit(X_train, y_train) # fit model\n",
    "\n",
    "\n",
    "print(\"*all digits, zero through nine*\")\n",
    "print()\n",
    "print(\"first 5 predictions:\", mlp.predict(X_test[0:5])) # first 5 predictions\n",
    "print(\"first 5 targets:    \", y_test[0:5]) # first 5 targets (actual values)\n",
    "print(\"model accuracy: \", mlp.score(X_test, y_test)) # model accuracy\n",
    "print()\n",
    "\n",
    "# looking at incorrect predictions\n",
    "y_pred = mlp.predict(X_test) # predictions for all testing datapoints\n",
    "wrong_pred_mask = (y_pred != y_test) # list of T/F values, T where test predictions don't match test targets\n",
    "incorrect_pred = y_pred[wrong_pred_mask] # mask applied to predictions, pulls out incorrect predictions \n",
    "incorrect_true = y_test[wrong_pred_mask] # mask applied to targets, pulls out actual values for wrong preds\n",
    "print(\"wrongly predicted values:\", incorrect_true) \n",
    "print(\"wrongly predicted as:    \", incorrect_pred)\n",
    "print()\n",
    "# we see the model had the most trouble with 4s and 9s \n",
    "\n",
    "# code and comments by github.com/alandavidgrunberg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
