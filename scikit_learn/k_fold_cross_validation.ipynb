{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b53469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Metrics change each run*\n",
      "accuracy: 0.8288\n",
      "precision: 0.7647\n",
      "recall: 0.7831\n",
      "f1 score: 0.7738\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['Male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'Male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) # no set random state, so different shuffle each time we run the code.\n",
    "\n",
    "# building the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"*Metrics change each run*\")\n",
    "print(f\"accuracy: {accuracy_score(y_test, y_pred):.4f}\") # f-string formatting\n",
    "print(f\"precision: {precision_score(y_test, y_pred):.4f}\") # ':.4f' = float with 4 digits after decimal point\n",
    "print(f\"recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_test, y_pred):.4f}\")\n",
    "# You can see that each time we run it, we get different values for the metrics, depending on how lucky or unlucky we were in which datapoints ended up in the test set. \n",
    "\n",
    "# The accuracy ranges from 0.79 to 0.84, the precision from 0.75 to 0.81 and the recall from 0.63 to 0.75. Wide range of possible values that could output, so hard to know how reliable our metrics are. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a95e5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ k-fold cross validation with just 2 features, 9 datapoints ___\n",
      "\n",
      "*k-fold chunks*\n",
      "[training set]             [testing set]\n",
      "(array([0, 2, 3, 4, 6, 8]), array([1, 5, 7]))\n",
      "(array([1, 3, 4, 5, 6, 7]), array([0, 2, 8]))\n",
      "(array([0, 1, 2, 5, 7, 8]), array([3, 4, 6]))\n",
      "\n",
      "*First chunk*\n",
      "training set indices: [0 2 3 4 6 8]\n",
      "test set indices: [1 5 7]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## k-fold cross validation\n",
    "\n",
    "# k-fold cross validation addresses this issue by breaking our dataset into multiple training and testing set chunks. Each datapoint will appear in the testing set one time. By averaging out the results from each training/testing chunk, we can be more confident in our metrics. \n",
    "\n",
    "# lets start with just 2 features and a much smaller dataset\n",
    "print('___ k-fold cross validation with just 2 features, 9 datapoints ___')\n",
    "print()\n",
    "\n",
    "X = df[['Age', 'Fare']].values[:9] # 'Age' & 'Fare' features selected, first 9 datapoints\n",
    "y = df['Survived'].values[:9] # target values, first 9 datapoints \n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42) # instantiate 'Kfold()' object, will split data into 3 chunks, 'shuffle' randomizes order, 'random_state' holds the shuffle\n",
    "chunk_generator = kf.split(X) # 'split()' method creates the splits, outputs a generator. pass features 'X', assign generator to 'chunk_generator' \n",
    "print(\"*k-fold chunks*\")\n",
    "print(\"[training set]             [testing set]\")\n",
    "for chunk in chunk_generator: # for loop to output the 3 chunks from the generator\n",
    "    print(chunk) # shows indices, not actual data values. each chunk has 6 datapoints in training set and 3 datapoints in testing set\n",
    "print()\n",
    "\n",
    "chunk_list = list(kf.split(X))  # 'split()' method creates the splits, outputs a generator. pass features 'X', turn generator into list, assign list to 'chunk_list'\n",
    "first_chunk = chunk_list[0] # pull out first chunk from list of chunks. contains an array of training indices and an array of testing indices \n",
    "train_indices, test_indices = first_chunk # unpack the two arrays to seperate variables\n",
    "print(\"*First chunk*\")\n",
    "print(\"training set indices:\", train_indices)\n",
    "print(\"test set indices:\", test_indices)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f9fa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[3 True 22.0 1 0 7.25]\n",
      " [3 False 26.0 0 0 7.925]\n",
      " [1 False 35.0 1 0 53.1]\n",
      " [3 True 35.0 0 0 8.05]\n",
      " [1 True 54.0 0 0 51.8625]\n",
      " [3 False 27.0 0 2 11.1333]]\n",
      "y_train: [0 1 1 0 0 1]\n",
      "\n",
      "X_test:\n",
      "[[1 False 38.0 1 0 71.2833]\n",
      " [3 True 27.0 0 0 8.4583]\n",
      " [3 True 2.0 3 1 21.075]]\n",
      "y_test: [1 0 0]\n",
      "\n",
      "accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# creating train/test-split based on the indices from first K-fold chunk\n",
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_test = y[test_indices]\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"y_train:\", y_train)\n",
    "print()\n",
    "print(\"X_test:\")\n",
    "print(X_test)\n",
    "print(\"y_test:\", y_test)\n",
    "print()\n",
    "\n",
    "# creating model for first K-fold chunk\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"accuracy:\", model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "744620c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*All 3 chunks*\n",
      "\n",
      "accuracy scores: [0.7359550561797753, 0.8258426966292135, 0.8022598870056498, 0.847457627118644, 0.7627118644067796]\n",
      "mean accuracy score: 0.7948454262680125\n"
     ]
    }
   ],
   "source": [
    "# weâ€™ve essentially done a single train/test split. \n",
    "#In order to do a k-fold cross validation, we need to use each of the other 2 splits to build a model and score the model.\n",
    "# loop over all the folds\n",
    "print(\"*All 3 chunks*\")\n",
    "print()\n",
    "list_of_scores = [] # create empty list 'list_of_scores' \n",
    "for train_index, test_index in kf.split(X): # 'split()' method creates the splits, outputs a generator, pass features X. for loop using training and testing indices generated for each chunk \n",
    "    X_train, X_test = X[train_index], X[test_index] # train/test-split for each chunk\n",
    "    y_train, y_test = y[train_index], y[test_index] # using training and testing indices \n",
    "    model = LogisticRegression() # instantiate model for each chunk\n",
    "    model.fit(X_train, y_train) # fit each model \n",
    "    list_of_scores.append(model.score(X_test, y_test)) # add each model's accuracy score to 'list_of_scores' \n",
    "print(\"accuracy scores:\", list_of_scores)\n",
    "print(\"mean accuracy score:\", np.mean(list_of_scores)) # find mean of all three model's scores. This is the cross-validated score we would report for the final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7fc0dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy scores: [0.85955056 0.74719101 0.8079096  0.81355932 0.78531073]\n",
      "mean accuracy score: 0.8027042468101314\n"
     ]
    }
   ],
   "source": [
    "# cross_val_score\n",
    "# no need to loop over all the folds manually! you can use 'cross_val_score' as a shortcut\n",
    "scores = cross_val_score(model, X, y, cv=kf) # pass model, all features 'X', all targets 'y' 'cv=' means number of folds. Instead of passing an integer, here we pass 'cv=kf'. 'kf' is the 'KFold' object that was initiated earlier with '(n_splits=3, shuffle=True, random_state=42)' \n",
    "# 'cross_val_score' will automatically create a train/test-split for each chunk, instantiate a model for each chunk, fit each model, and output each model's accuracy score\n",
    "print('accuracy scores:', scores)\n",
    "print(\"mean accuracy score:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe55e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ k-fold cross validation with all 6 features and entire dataset ___\n",
      "\n",
      "accuracy scores: [0.79775281 0.78651685 0.77966102 0.79096045 0.81355932]\n",
      "mean accuracy score: 0.7936900907763602\n",
      "\n",
      "accuracy scores: [0.797752808988764, 0.8033707865168539, 0.7740112994350282, 0.8022598870056498, 0.807909604519774]\n",
      "mean accuracy score: 0.797060877293214\n"
     ]
    }
   ],
   "source": [
    "# now lets do k-fold cross validation using all 6 features and the entire dataset \n",
    "print('___ k-fold cross validation with all 6 features and entire dataset ___')\n",
    "print()\n",
    "\n",
    "model = LogisticRegression()\n",
    "X = df[['Pclass', 'Male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "# cross_val_score shortcut\n",
    "scores = cross_val_score(model, X, y, cv=5) # 5 folds this time (no set random state)\n",
    "print('accuracy scores:', scores)\n",
    "print(\"mean accuracy score:\", np.mean(scores))\n",
    "print()\n",
    "\n",
    "# loop over all folds\n",
    "kf = KFold(n_splits=5, shuffle=True) # instantiate 'Kfold()' object, will split data into 5 chunks, 'shuffle' randomizes order, (no set random state)\n",
    "list_of_scores = [] # create empty list 'list_of_scores' \n",
    "for train_index, test_index in kf.split(X): # 'split()' method creates the splits, outputs a generator, pass features X. for loop using training and testing indices generated for each chunk \n",
    "    X_train, X_test = X[train_index], X[test_index] # train/test-split for each chunk\n",
    "    y_train, y_test = y[train_index], y[test_index] # using training and testing indices \n",
    "    model = LogisticRegression() # instantiate model for each chunk\n",
    "    model.fit(X_train, y_train) # fit each model \n",
    "    list_of_scores.append(model.score(X_test, y_test)) # add each model's accuracy score to 'list_of_scores'\n",
    "print(\"accuracy scores:\", list_of_scores)\n",
    "print(\"mean accuracy score:\", np.mean(list_of_scores)) # find mean of all 5 model's scores. This is the cross-validated score we would report for the final model\n",
    "# notice slight difference between results from 'cross_val_score' shortcut and results from manually looping over the folds. \n",
    "#That's because we did not set a matching random state. We also get slightly different results each time we run the code. However, the mean accuracy scores should be quite close and not fluctuate much each run. That's what k-fold cross validation is for!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8441e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy scores: [0.797752808988764, 0.8146067415730337, 0.7796610169491526, 0.8135593220338984, 0.7853107344632768]\n",
      "precision scores: [0.7142857142857143, 0.7878787878787878, 0.746031746031746, 0.7313432835820896, 0.8305084745762712]\n",
      "recall scores: [0.6666666666666666, 0.7323943661971831, 0.6714285714285714, 0.765625, 0.6363636363636364]\n",
      "f1 scores: [0.689655172413793, 0.7591240875912407, 0.706766917293233, 0.748091603053435, 0.7205882352941178]\n",
      "\n",
      "mean accuracy: 0.7982\n",
      "mean precision: 0.7620\n",
      "mean recall: 0.6945\n",
      "mean f1 score: 0.7248\n"
     ]
    }
   ],
   "source": [
    "# loop over all folds again\n",
    "# this time outputting predictions to get more metrics\n",
    "kf = KFold(n_splits=5, shuffle=True) # instantiate 'Kfold()' object, will split data into 5 chunks, 'shuffle' randomizes order, (no set random state)\n",
    "list_of_accuracy_scores = [] # create empty lists for each metric\n",
    "list_of_precision_scores = []\n",
    "list_of_recall_scores = []\n",
    "list_of_f1_scores = []\n",
    "for train_index, test_index in kf.split(X): # 'split()' method creates the splits, outputs a generator, pass features X. for loop using training and testing indices generated for each chunk \n",
    "    X_train, X_test = X[train_index], X[test_index] # train/test-split for each chunk\n",
    "    y_train, y_test = y[train_index], y[test_index] # using training and testing indices \n",
    "    model = LogisticRegression() # instantiate model for each chunk\n",
    "    model.fit(X_train, y_train) # fit each model \n",
    "    y_pred = model.predict(X_test) # get predictions for each model\n",
    "    list_of_accuracy_scores.append(accuracy_score(y_test, y_pred)) # passing each model's targets and predictions to get metrics\n",
    "    list_of_precision_scores.append(precision_score(y_test, y_pred)) # and adding each model's metrics to respective lists\n",
    "    list_of_recall_scores.append(recall_score(y_test, y_pred))\n",
    "    list_of_f1_scores.append(f1_score(y_test, y_pred))\n",
    "print(\"accuracy scores:\", list_of_accuracy_scores)\n",
    "print(\"precision scores:\", list_of_precision_scores)\n",
    "print(\"recall scores:\", list_of_recall_scores)\n",
    "print(\"f1 scores:\", list_of_f1_scores)\n",
    "print()\n",
    "print(f\"mean accuracy: {np.mean(list_of_accuracy_scores):.4f}\") # f-string formatting\n",
    "print(f\"mean precision: {np.mean(list_of_precision_scores):.4f}\") # ':.4f' = float with 4 digits after decimal point\n",
    "print(f\"mean recall: {np.mean(list_of_recall_scores):.4f}\")\n",
    "print(f\"mean f1 score: {np.mean(list_of_f1_scores):.4f}\")\n",
    "\n",
    "# These metrics results are more reliable than the results from a single train/test split, because they are the cross validated results of 5 different train/test splits! \n",
    "\n",
    "# code and comments by github.com/alandavidgrunberg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
